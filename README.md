# multi-armed-bandits (MAB)

A brief yet systematic look at popular MAB algorithms.

### Abstract
The multi-armed bandit (MAB) problem was originally about slot machines. A gambler tries to maximize his rewards from playing a slot machine that has K pulling arms. Each arm has a reward distribution (i.e., success rate) that is unknown to the gambler. What are some different strategies the gambler can play to take home the most rewards before his money runs out or the casino closes? In this article, we would like to take the opportunity to investigate what the Multi-Armed Bandit problem is and what some effective algorithms to approach the problem are. The multi-armed bandit problem is important as its problem setting extends to other sequential decision-making challenges (e.g., clinical trails, infor- mation retrieval, and portfolio choice). Thus, we also share the progress of some promising applications facilitated by these bandit algorithms as well as some remaining open problems and future potentials.

